{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/deployment/deploy-multi-model/multi-model-register-and-deploy.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy Multiple Models as Webservice\n",
        "\n",
        "This example shows how to deploy a Webservice with multiple models in step-by-step fashion:\n",
        "\n",
        " 1. Register Models\n",
        " 2. Deploy Models as Webservice"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the [configuration](../../../configuration.ipynb) Notebook first if you haven't."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.22.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1623248604370
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace\n",
        "\n",
        "Initialize a workspace object from persisted configuration."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fmoz-workspace\n",
            "ml\n",
            "westus2\n",
            "421b563f-a977-42aa-8934-f41ca5664b73\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "tags": [
          "create workspace"
        ],
        "gather": {
          "logged": 1623248604737
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will be using and registering two models. \n",
        "\n",
        "First we will train two simple models on the [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset) included with scikit-learn, serializing them to files in the current directory."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import sklearn\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import BayesianRidge, Ridge\n",
        "\n",
        "x, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "first_model = Ridge().fit(x, y)\n",
        "second_model = BayesianRidge().fit(x, y)\n",
        "\n",
        "joblib.dump(first_model, \"first_model.pkl\")\n",
        "joblib.dump(second_model, \"second_model.pkl\")\n",
        "\n",
        "print(\"Trained models using scikit-learn {}.\".format(sklearn.__version__))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained models using scikit-learn 0.22.2.post1.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1623248605217
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our trained models locally, we will register them as Models with the names `my_first_model` and `my_second_model` in the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "my_model_1 = Model.register(model_path=\"first_model.pkl\",\n",
        "                            model_name=\"my_first_model\",\n",
        "                            workspace=ws)\n",
        "\n",
        "my_model_2 = Model.register(model_path=\"second_model.pkl\",\n",
        "                            model_name=\"my_second_model\",\n",
        "                            workspace=ws)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model my_first_model\n",
            "Registering model my_second_model\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "tags": [
          "register model from file"
        ],
        "gather": {
          "logged": 1623248607499
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write the Entry Script\n",
        "Write the script that will be used to predict on your models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model.get_model_path()\n",
        "\n",
        "To get the paths of your models, use `Model.get_model_path(model_name, version=None, _workspace=None)` method. This method will find the path to a model using the name of the model registered under the workspace.\n",
        "\n",
        "In this example, we do not use the optional arguments `version` and `_workspace`.\n",
        "\n",
        "#### Using environment variable AZUREML_MODEL_DIR\n",
        "\n",
        "In other [examples](../deploy-to-cloud/score.py) with a single model deployment, we use the environment variable `AZUREML_MODEL_DIR` and model file name to get the model path. \n",
        "\n",
        "For single model deployments, this environment variable is the path to the model folder (`./azureml-models/$MODEL_NAME/$VERSION`). When we deploy multiple models, the environment variable is set to the folder containing all models (./azureml-models).\n",
        "\n",
        "If you're using multiple models and you know the versions of the models you deploy, you can use this method to get the model path:\n",
        "\n",
        "```python\n",
        "# Construct the model path using the registered model name, version, and model file name\n",
        "model_1_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'my_first_model', '1', 'first_model.pkl')\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "import joblib\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "def init():\n",
        "    global model_1, model_2\n",
        "    # Here \"my_first_model\" is the name of the model registered under the workspace.\n",
        "    # This call will return the path to the .pkl file on the local disk.\n",
        "    model_1_path = Model.get_model_path(model_name='my_first_model')\n",
        "    model_2_path = Model.get_model_path(model_name='my_second_model')\n",
        "    \n",
        "    # Deserialize the model files back into scikit-learn models.\n",
        "    model_1 = joblib.load(model_1_path)\n",
        "    model_2 = joblib.load(model_2_path)\n",
        "\n",
        "# Note you can pass in multiple rows for scoring.\n",
        "def run(raw_data):\n",
        "    try:\n",
        "        data = json.loads(raw_data)['data']\n",
        "        data = np.array(data)\n",
        "        \n",
        "        # Call predict() on each model\n",
        "        result_1 = model_1.predict(data)\n",
        "        result_2 = model_2.predict(data)\n",
        "\n",
        "        # You can return any JSON-serializable value.\n",
        "        return {\"prediction1\": result_1.tolist(), \"prediction2\": result_2.tolist()}\n",
        "    except Exception as e:\n",
        "        result = str(e)\n",
        "        return result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now create and/or use an Environment object when deploying a Webservice. The Environment can have been previously registered with your Workspace, or it will be registered with it as a part of the Webservice deployment. Please note that your environment must include azureml-defaults with verion >= 1.0.45 as a pip dependency, because it contains the functionality needed to host the model as a web service.\n",
        "\n",
        "More information can be found in our [using environments notebook](../training/using-environments/using-environments.ipynb)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment(\"deploytocloudenv\")\n",
        "env.python.conda_dependencies.add_pip_package(\"joblib\")\n",
        "env.python.conda_dependencies.add_pip_package(\"numpy\")\n",
        "env.python.conda_dependencies.add_pip_package(\"scikit-learn=={}\".format(sklearn.__version__))"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1623248608058
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Inference Configuration\n",
        "\n",
        "There is now support for a source directory, you can upload an entire folder from your local machine as dependencies for the Webservice.\n",
        "Note: in that case, environments's entry_script and file_path are relative paths to the source_directory path; myenv.docker.base_dockerfile is a string containing extra docker steps or contents of the docker file.\n",
        "\n",
        "Sample code for using a source directory:\n",
        "\n",
        "```python\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "myenv = Environment.from_conda_specification(name='myenv', file_path='env/myenv.yml')\n",
        "\n",
        "# explicitly set base_image to None when setting base_dockerfile\n",
        "myenv.docker.base_image = None\n",
        "# add extra docker commends to execute\n",
        "myenv.docker.base_dockerfile = \"FROM ubuntu\\n RUN echo \\\"hello\\\"\"\n",
        "\n",
        "inference_config = InferenceConfig(source_directory=\"C:/abc\",\n",
        "                                   entry_script=\"x/y/score.py\",\n",
        "                                   environment=myenv)\n",
        "```\n",
        "\n",
        " - file_path: input parameter to Environment constructor. Manages conda and python package dependencies.\n",
        " - env.docker.base_dockerfile: any extra steps you want to inject into docker file\n",
        " - source_directory: holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\n",
        " - entry_script: contains logic specific to initializing your model and running predictions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "tags": [
          "create image"
        ],
        "gather": {
          "logged": 1623248608289
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deploy Model as Webservice on Azure Container Instance\n",
        "\n",
        "Note that the service creation can take few minutes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aci_service_name = \"aciservice-multimodel\"\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
        "\n",
        "service = Model.deploy(ws, aci_service_name, [my_model_1, my_model_2], inference_config, deployment_config, overwrite=True)\n",
        "service.wait_for_deployment(True)\n",
        "\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running....................................................."
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "tags": [
          "azuremlexception-remarks-sample"
        ]
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test web service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data': x[0:2].tolist()})\n",
        "\n",
        "prediction = service.run(test_sample)\n",
        "\n",
        "print(prediction)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Delete ACI to clean up"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [
          "deploy service",
          "aci"
        ]
      }
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "jenns"
      }
    ],
    "categories": [
      "how-to-use-azureml",
      "deployment"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}